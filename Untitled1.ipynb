{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "from sklearn.datasets import make_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "from matplotlib.widgets import Slider\n",
    "#from lab_utils_common import dlc\n",
    "#from lab_utils_softmax import plt_softmax\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "Temp_Data = pd.read_csv('C:/Users/pierr/OneDrive/Desktop/Temp_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = Temp_Data.iloc[0:2000,0]\n",
    "train_y = Temp_Data.iloc[0:2000,1]\n",
    "test_X = Temp_Data.iloc[0:500,0]\n",
    "test_y = Temp_Data.iloc[0:500,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2000,)\n",
      "Y_train: (2000,)\n",
      "X_test:  (500,)\n",
      "Y_test:  (500,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_model = Sequential(\n",
    "    [\n",
    "        Dense(1),\n",
    "        Dense(1,activation ='linear')\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "digit_model.compile(loss='mean_squared_error',\n",
    "                    optimizer = 'rmsprop', \n",
    "                    metrics = ['accuracy']\n",
    "                   )\n",
    "\n",
    "\n",
    "#digit_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy() )\n",
    "#keras.optimizers.RMSprop(learning_rate = 0.001, rho = 0.9)\n",
    "#digit_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 95680.9297 - accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "63/63 [==============================] - 0s 779us/step - loss: 87182.0078 - accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "63/63 [==============================] - 0s 807us/step - loss: 79737.6562 - accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "63/63 [==============================] - 0s 861us/step - loss: 73020.3047 - accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "63/63 [==============================] - 0s 783us/step - loss: 67005.7969 - accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "63/63 [==============================] - 0s 804us/step - loss: 61533.5391 - accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "63/63 [==============================] - 0s 829us/step - loss: 56722.5469 - accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "63/63 [==============================] - 0s 988us/step - loss: 52416.0430 - accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "63/63 [==============================] - 0s 820us/step - loss: 48715.5352 - accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "63/63 [==============================] - 0s 959us/step - loss: 45443.6602 - accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 42597.0703 - accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "63/63 [==============================] - 0s 983us/step - loss: 40146.6289 - accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 38075.2969 - accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "63/63 [==============================] - 0s 853us/step - loss: 36343.7344 - accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "63/63 [==============================] - 0s 918us/step - loss: 34910.0234 - accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "63/63 [==============================] - 0s 792us/step - loss: 33804.3906 - accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "63/63 [==============================] - 0s 793us/step - loss: 32922.9570 - accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "63/63 [==============================] - 0s 885us/step - loss: 31932.4863 - accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "63/63 [==============================] - 0s 885us/step - loss: 30660.8145 - accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "63/63 [==============================] - 0s 792us/step - loss: 29138.4004 - accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "63/63 [==============================] - 0s 861us/step - loss: 27385.3184 - accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "63/63 [==============================] - 0s 863us/step - loss: 25448.9629 - accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "63/63 [==============================] - 0s 819us/step - loss: 23353.5859 - accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "63/63 [==============================] - 0s 877us/step - loss: 21124.8223 - accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "63/63 [==============================] - 0s 881us/step - loss: 18802.3203 - accuracy: 0.0000e+00\n",
      "Epoch 26/300\n",
      "63/63 [==============================] - 0s 861us/step - loss: 16426.7266 - accuracy: 0.0000e+00\n",
      "Epoch 27/300\n",
      "63/63 [==============================] - 0s 941us/step - loss: 14053.6689 - accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      "63/63 [==============================] - 0s 930us/step - loss: 11697.0264 - accuracy: 0.0000e+00\n",
      "Epoch 29/300\n",
      "63/63 [==============================] - 0s 844us/step - loss: 9438.6162 - accuracy: 0.0000e+00\n",
      "Epoch 30/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 7345.8970 - accuracy: 0.0000e+00\n",
      "Epoch 31/300\n",
      "63/63 [==============================] - 0s 892us/step - loss: 5464.0913 - accuracy: 0.0000e+00\n",
      "Epoch 32/300\n",
      "63/63 [==============================] - 0s 877us/step - loss: 3806.1733 - accuracy: 0.0000e+00\n",
      "Epoch 33/300\n",
      "63/63 [==============================] - 0s 846us/step - loss: 2519.4702 - accuracy: 0.0000e+00\n",
      "Epoch 34/300\n",
      "63/63 [==============================] - 0s 967us/step - loss: 1600.8910 - accuracy: 0.0000e+00\n",
      "Epoch 35/300\n",
      "63/63 [==============================] - 0s 909us/step - loss: 1102.2635 - accuracy: 0.0000e+00\n",
      "Epoch 36/300\n",
      "63/63 [==============================] - 0s 810us/step - loss: 970.0345 - accuracy: 0.0000e+00\n",
      "Epoch 37/300\n",
      "63/63 [==============================] - 0s 822us/step - loss: 958.3345 - accuracy: 0.0000e+00\n",
      "Epoch 38/300\n",
      "63/63 [==============================] - 0s 933us/step - loss: 948.3787 - accuracy: 0.0000e+00\n",
      "Epoch 39/300\n",
      "63/63 [==============================] - 0s 810us/step - loss: 939.7941 - accuracy: 0.0000e+00\n",
      "Epoch 40/300\n",
      "63/63 [==============================] - 0s 887us/step - loss: 929.2115 - accuracy: 0.0000e+00\n",
      "Epoch 41/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 920.7253 - accuracy: 0.0000e+00\n",
      "Epoch 42/300\n",
      "63/63 [==============================] - 0s 934us/step - loss: 911.3378 - accuracy: 0.0000e+00\n",
      "Epoch 43/300\n",
      "63/63 [==============================] - 0s 865us/step - loss: 901.5941 - accuracy: 0.0000e+00\n",
      "Epoch 44/300\n",
      "63/63 [==============================] - 0s 857us/step - loss: 891.6912 - accuracy: 0.0000e+00\n",
      "Epoch 45/300\n",
      "63/63 [==============================] - 0s 926us/step - loss: 882.9403 - accuracy: 0.0000e+00\n",
      "Epoch 46/300\n",
      "63/63 [==============================] - 0s 809us/step - loss: 874.0293 - accuracy: 0.0000e+00\n",
      "Epoch 47/300\n",
      "63/63 [==============================] - 0s 957us/step - loss: 864.7751 - accuracy: 0.0000e+00\n",
      "Epoch 48/300\n",
      "63/63 [==============================] - 0s 884us/step - loss: 855.8577 - accuracy: 0.0000e+00\n",
      "Epoch 49/300\n",
      "63/63 [==============================] - 0s 983us/step - loss: 846.2637 - accuracy: 0.0000e+00\n",
      "Epoch 50/300\n",
      "63/63 [==============================] - 0s 955us/step - loss: 836.9044 - accuracy: 0.0000e+00\n",
      "Epoch 51/300\n",
      "63/63 [==============================] - 0s 849us/step - loss: 828.2883 - accuracy: 0.0000e+00\n",
      "Epoch 52/300\n",
      "63/63 [==============================] - 0s 950us/step - loss: 819.3447 - accuracy: 0.0000e+00\n",
      "Epoch 53/300\n",
      "63/63 [==============================] - 0s 926us/step - loss: 810.3657 - accuracy: 0.0000e+00\n",
      "Epoch 54/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 801.5364 - accuracy: 0.0000e+00\n",
      "Epoch 55/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 792.1411 - accuracy: 0.0000e+00\n",
      "Epoch 56/300\n",
      "63/63 [==============================] - 0s 955us/step - loss: 783.2647 - accuracy: 0.0000e+00\n",
      "Epoch 57/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 774.4639 - accuracy: 0.0000e+00\n",
      "Epoch 58/300\n",
      "63/63 [==============================] - 0s 839us/step - loss: 765.6011 - accuracy: 0.0000e+00\n",
      "Epoch 59/300\n",
      "63/63 [==============================] - 0s 820us/step - loss: 756.5137 - accuracy: 0.0000e+00\n",
      "Epoch 60/300\n",
      "63/63 [==============================] - 0s 804us/step - loss: 747.6938 - accuracy: 0.0000e+00\n",
      "Epoch 61/300\n",
      "63/63 [==============================] - 0s 941us/step - loss: 739.1556 - accuracy: 0.0000e+00\n",
      "Epoch 62/300\n",
      "63/63 [==============================] - 0s 898us/step - loss: 730.4945 - accuracy: 0.0000e+00\n",
      "Epoch 63/300\n",
      "63/63 [==============================] - 0s 974us/step - loss: 721.0125 - accuracy: 0.0000e+00\n",
      "Epoch 64/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 712.5121 - accuracy: 0.0000e+00\n",
      "Epoch 65/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 703.7890 - accuracy: 0.0000e+00\n",
      "Epoch 66/300\n",
      "63/63 [==============================] - 0s 957us/step - loss: 695.0140 - accuracy: 0.0000e+00\n",
      "Epoch 67/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 685.9449 - accuracy: 0.0000e+00\n",
      "Epoch 68/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 678.2733 - accuracy: 0.0000e+00\n",
      "Epoch 69/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 669.1832 - accuracy: 0.0000e+00\n",
      "Epoch 70/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 660.6735 - accuracy: 0.0000e+00\n",
      "Epoch 71/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 651.8635 - accuracy: 0.0000e+00\n",
      "Epoch 72/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 643.5425 - accuracy: 0.0000e+00\n",
      "Epoch 73/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 635.3307 - accuracy: 0.0000e+00\n",
      "Epoch 74/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 625.7977 - accuracy: 0.0000e+00\n",
      "Epoch 75/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 617.6929 - accuracy: 0.0000e+00\n",
      "Epoch 76/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 608.9279 - accuracy: 0.0000e+00\n",
      "Epoch 77/300\n",
      "63/63 [==============================] - 0s 853us/step - loss: 599.8822 - accuracy: 0.0000e+00\n",
      "Epoch 78/300\n",
      "63/63 [==============================] - 0s 877us/step - loss: 592.1875 - accuracy: 0.0000e+00\n",
      "Epoch 79/300\n",
      "63/63 [==============================] - 0s 935us/step - loss: 583.5638 - accuracy: 0.0000e+00\n",
      "Epoch 80/300\n",
      "63/63 [==============================] - 0s 861us/step - loss: 574.9164 - accuracy: 0.0000e+00\n",
      "Epoch 81/300\n",
      "63/63 [==============================] - 0s 951us/step - loss: 566.6306 - accuracy: 0.0000e+00\n",
      "Epoch 82/300\n",
      "63/63 [==============================] - 0s 885us/step - loss: 557.9805 - accuracy: 0.0000e+00\n",
      "Epoch 83/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 549.7476 - accuracy: 0.0000e+00\n",
      "Epoch 84/300\n",
      "63/63 [==============================] - 0s 853us/step - loss: 540.6993 - accuracy: 0.0000e+00\n",
      "Epoch 85/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 532.8764 - accuracy: 0.0000e+00\n",
      "Epoch 86/300\n",
      "63/63 [==============================] - 0s 813us/step - loss: 524.1425 - accuracy: 0.0000e+00\n",
      "Epoch 87/300\n",
      "63/63 [==============================] - 0s 901us/step - loss: 515.9420 - accuracy: 0.0000e+00\n",
      "Epoch 88/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 506.6121 - accuracy: 0.0000e+00\n",
      "Epoch 89/300\n",
      "63/63 [==============================] - 0s 994us/step - loss: 498.6508 - accuracy: 0.0000e+00\n",
      "Epoch 90/300\n",
      "63/63 [==============================] - 0s 885us/step - loss: 489.7617 - accuracy: 0.0000e+00\n",
      "Epoch 91/300\n",
      "63/63 [==============================] - 0s 941us/step - loss: 481.7699 - accuracy: 0.0000e+00\n",
      "Epoch 92/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 473.4524 - accuracy: 0.0000e+00\n",
      "Epoch 93/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 463.8864 - accuracy: 0.0000e+00\n",
      "Epoch 94/300\n",
      "63/63 [==============================] - 0s 925us/step - loss: 456.4258 - accuracy: 0.0000e+00\n",
      "Epoch 95/300\n",
      "63/63 [==============================] - 0s 933us/step - loss: 447.9942 - accuracy: 0.0000e+00\n",
      "Epoch 96/300\n",
      "63/63 [==============================] - 0s 852us/step - loss: 439.2580 - accuracy: 0.0000e+00\n",
      "Epoch 97/300\n",
      "63/63 [==============================] - 0s 957us/step - loss: 431.3674 - accuracy: 0.0000e+00\n",
      "Epoch 98/300\n",
      "63/63 [==============================] - 0s 949us/step - loss: 422.6603 - accuracy: 0.0000e+00\n",
      "Epoch 99/300\n",
      "63/63 [==============================] - 0s 866us/step - loss: 414.3634 - accuracy: 0.0000e+00\n",
      "Epoch 100/300\n",
      "63/63 [==============================] - 0s 884us/step - loss: 405.8970 - accuracy: 0.0000e+00\n",
      "Epoch 101/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 397.2798 - accuracy: 0.0000e+00\n",
      "Epoch 102/300\n",
      "63/63 [==============================] - 0s 893us/step - loss: 389.0705 - accuracy: 0.0000e+00\n",
      "Epoch 103/300\n",
      "63/63 [==============================] - 0s 804us/step - loss: 380.7202 - accuracy: 0.0000e+00\n",
      "Epoch 104/300\n",
      "63/63 [==============================] - 0s 909us/step - loss: 372.3734 - accuracy: 0.0000e+00\n",
      "Epoch 105/300\n",
      "63/63 [==============================] - 0s 820us/step - loss: 363.2180 - accuracy: 0.0000e+00\n",
      "Epoch 106/300\n",
      "63/63 [==============================] - 0s 813us/step - loss: 355.8040 - accuracy: 0.0000e+00\n",
      "Epoch 107/300\n",
      "63/63 [==============================] - 0s 904us/step - loss: 346.9667 - accuracy: 0.0000e+00\n",
      "Epoch 108/300\n",
      "63/63 [==============================] - 0s 981us/step - loss: 338.8881 - accuracy: 0.0000e+00\n",
      "Epoch 109/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 330.6066 - accuracy: 0.0000e+00\n",
      "Epoch 110/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 322.1447 - accuracy: 0.0000e+00\n",
      "Epoch 111/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 313.7255 - accuracy: 0.0000e+00\n",
      "Epoch 112/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 305.3860 - accuracy: 0.0000e+00\n",
      "Epoch 113/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 297.3345 - accuracy: 0.0000e+00\n",
      "Epoch 114/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 289.2737 - accuracy: 0.0000e+00\n",
      "Epoch 115/300\n",
      "63/63 [==============================] - 0s 921us/step - loss: 280.5395 - accuracy: 0.0000e+00\n",
      "Epoch 116/300\n",
      "63/63 [==============================] - 0s 987us/step - loss: 272.4376 - accuracy: 0.0000e+00\n",
      "Epoch 117/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 264.4929 - accuracy: 0.0000e+00\n",
      "Epoch 118/300\n",
      "63/63 [==============================] - 0s 885us/step - loss: 255.6987 - accuracy: 0.0000e+00\n",
      "Epoch 119/300\n",
      "63/63 [==============================] - 0s 918us/step - loss: 247.9525 - accuracy: 0.0000e+00\n",
      "Epoch 120/300\n",
      "63/63 [==============================] - 0s 901us/step - loss: 239.5744 - accuracy: 0.0000e+00\n",
      "Epoch 121/300\n",
      "63/63 [==============================] - 0s 893us/step - loss: 231.4134 - accuracy: 0.0000e+00\n",
      "Epoch 122/300\n",
      "63/63 [==============================] - 0s 934us/step - loss: 223.5931 - accuracy: 0.0000e+00\n",
      "Epoch 123/300\n",
      "63/63 [==============================] - 0s 865us/step - loss: 215.6712 - accuracy: 0.0000e+00\n",
      "Epoch 124/300\n",
      "63/63 [==============================] - 0s 987us/step - loss: 207.8104 - accuracy: 0.0000e+00\n",
      "Epoch 125/300\n",
      "63/63 [==============================] - 0s 853us/step - loss: 200.2820 - accuracy: 0.0000e+00\n",
      "Epoch 126/300\n",
      "63/63 [==============================] - 0s 890us/step - loss: 192.5582 - accuracy: 0.0000e+00\n",
      "Epoch 127/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 184.7359 - accuracy: 0.0000e+00\n",
      "Epoch 128/300\n",
      "63/63 [==============================] - 0s 884us/step - loss: 177.2285 - accuracy: 0.0000e+00\n",
      "Epoch 129/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 169.7176 - accuracy: 0.0000e+00\n",
      "Epoch 130/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 162.4640 - accuracy: 0.0000e+00\n",
      "Epoch 131/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 154.8307 - accuracy: 0.0000e+00\n",
      "Epoch 132/300\n",
      "63/63 [==============================] - 0s 941us/step - loss: 147.1412 - accuracy: 0.0000e+00\n",
      "Epoch 133/300\n",
      "63/63 [==============================] - 0s 885us/step - loss: 139.8601 - accuracy: 0.0000e+00\n",
      "Epoch 134/300\n",
      "63/63 [==============================] - 0s 893us/step - loss: 133.1262 - accuracy: 0.0000e+00\n",
      "Epoch 135/300\n",
      "63/63 [==============================] - 0s 941us/step - loss: 125.9254 - accuracy: 0.0000e+00\n",
      "Epoch 136/300\n",
      "63/63 [==============================] - 0s 965us/step - loss: 118.8868 - accuracy: 0.0000e+00\n",
      "Epoch 137/300\n",
      "63/63 [==============================] - 0s 957us/step - loss: 112.0192 - accuracy: 0.0000e+00\n",
      "Epoch 138/300\n",
      "63/63 [==============================] - 0s 949us/step - loss: 105.0908 - accuracy: 0.0000e+00\n",
      "Epoch 139/300\n",
      "63/63 [==============================] - 0s 822us/step - loss: 98.5297 - accuracy: 0.0000e+00\n",
      "Epoch 140/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 92.1481 - accuracy: 0.0000e+00\n",
      "Epoch 141/300\n",
      "63/63 [==============================] - 0s 937us/step - loss: 85.5562 - accuracy: 0.0000e+00\n",
      "Epoch 142/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 79.6706 - accuracy: 0.0000e+00\n",
      "Epoch 143/300\n",
      "63/63 [==============================] - 0s 997us/step - loss: 73.4583 - accuracy: 0.0000e+00\n",
      "Epoch 144/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 67.4608 - accuracy: 0.0000e+00\n",
      "Epoch 145/300\n",
      "63/63 [==============================] - 0s 895us/step - loss: 61.4680 - accuracy: 0.0000e+00\n",
      "Epoch 146/300\n",
      "63/63 [==============================] - 0s 898us/step - loss: 55.7272 - accuracy: 0.0000e+00\n",
      "Epoch 147/300\n",
      "63/63 [==============================] - 0s 853us/step - loss: 50.4532 - accuracy: 0.0000e+00\n",
      "Epoch 148/300\n",
      "63/63 [==============================] - 0s 893us/step - loss: 45.1640 - accuracy: 0.0000e+00\n",
      "Epoch 149/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 40.2625 - accuracy: 0.0000e+00\n",
      "Epoch 150/300\n",
      "63/63 [==============================] - 0s 981us/step - loss: 35.5472 - accuracy: 0.0000e+00\n",
      "Epoch 151/300\n",
      "63/63 [==============================] - 0s 922us/step - loss: 30.9325 - accuracy: 0.0000e+00\n",
      "Epoch 152/300\n",
      "63/63 [==============================] - 0s 933us/step - loss: 26.3654 - accuracy: 0.0000e+00\n",
      "Epoch 153/300\n",
      "63/63 [==============================] - 0s 887us/step - loss: 22.5444 - accuracy: 0.0000e+00\n",
      "Epoch 154/300\n",
      "63/63 [==============================] - 0s 990us/step - loss: 18.9609 - accuracy: 0.0000e+00\n",
      "Epoch 155/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 15.5739 - accuracy: 0.0000e+00\n",
      "Epoch 156/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 12.3422 - accuracy: 0.0000e+00\n",
      "Epoch 157/300\n",
      "63/63 [==============================] - 0s 909us/step - loss: 9.4880 - accuracy: 0.0000e+00\n",
      "Epoch 158/300\n",
      "63/63 [==============================] - 0s 885us/step - loss: 7.1058 - accuracy: 0.0000e+00\n",
      "Epoch 159/300\n",
      "63/63 [==============================] - 0s 845us/step - loss: 5.0560 - accuracy: 0.0000e+00\n",
      "Epoch 160/300\n",
      "63/63 [==============================] - 0s 804us/step - loss: 3.2965 - accuracy: 0.0000e+00\n",
      "Epoch 161/300\n",
      "63/63 [==============================] - 0s 974us/step - loss: 1.9598 - accuracy: 0.0000e+00\n",
      "Epoch 162/300\n",
      "63/63 [==============================] - 0s 925us/step - loss: 0.9938 - accuracy: 0.0000e+00\n",
      "Epoch 163/300\n",
      "63/63 [==============================] - 0s 892us/step - loss: 0.3973 - accuracy: 0.0000e+00\n",
      "Epoch 164/300\n",
      "63/63 [==============================] - 0s 821us/step - loss: 0.1085 - accuracy: 0.0000e+00\n",
      "Epoch 165/300\n",
      "63/63 [==============================] - 0s 798us/step - loss: 0.0391 - accuracy: 0.0000e+00\n",
      "Epoch 166/300\n",
      "63/63 [==============================] - 0s 842us/step - loss: 0.0307 - accuracy: 0.0000e+00\n",
      "Epoch 167/300\n",
      "63/63 [==============================] - 0s 925us/step - loss: 0.0278 - accuracy: 0.0000e+00\n",
      "Epoch 168/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.0000e+00\n",
      "Epoch 169/300\n",
      "63/63 [==============================] - 0s 916us/step - loss: 0.0289 - accuracy: 0.0000e+00\n",
      "Epoch 170/300\n",
      "63/63 [==============================] - 0s 884us/step - loss: 0.0349 - accuracy: 0.0000e+00\n",
      "Epoch 171/300\n",
      "63/63 [==============================] - 0s 861us/step - loss: 0.0312 - accuracy: 0.0000e+00\n",
      "Epoch 172/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.0000e+00\n",
      "Epoch 173/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.0000e+00\n",
      "Epoch 174/300\n",
      "63/63 [==============================] - 0s 905us/step - loss: 0.0279 - accuracy: 0.0000e+00\n",
      "Epoch 175/300\n",
      "63/63 [==============================] - 0s 845us/step - loss: 0.0366 - accuracy: 0.0000e+00\n",
      "Epoch 176/300\n",
      "63/63 [==============================] - 0s 818us/step - loss: 0.0293 - accuracy: 0.0000e+00\n",
      "Epoch 177/300\n",
      "63/63 [==============================] - 0s 941us/step - loss: 0.0304 - accuracy: 0.0000e+00\n",
      "Epoch 178/300\n",
      "63/63 [==============================] - 0s 979us/step - loss: 0.0327 - accuracy: 0.0000e+00\n",
      "Epoch 179/300\n",
      "63/63 [==============================] - 0s 969us/step - loss: 0.0323 - accuracy: 0.0000e+00\n",
      "Epoch 180/300\n",
      "63/63 [==============================] - 0s 974us/step - loss: 0.0263 - accuracy: 0.0000e+00\n",
      "Epoch 181/300\n",
      "63/63 [==============================] - 0s 949us/step - loss: 0.0336 - accuracy: 0.0000e+00\n",
      "Epoch 182/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.0000e+00\n",
      "Epoch 183/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.0000e+00\n",
      "Epoch 184/300\n",
      "63/63 [==============================] - 0s 978us/step - loss: 0.0337 - accuracy: 0.0000e+00\n",
      "Epoch 185/300\n",
      "63/63 [==============================] - 0s 877us/step - loss: 0.0327 - accuracy: 0.0000e+00\n",
      "Epoch 186/300\n",
      "63/63 [==============================] - 0s 859us/step - loss: 0.0261 - accuracy: 0.0000e+00\n",
      "Epoch 187/300\n",
      "63/63 [==============================] - 0s 991us/step - loss: 0.0335 - accuracy: 0.0000e+00\n",
      "Epoch 188/300\n",
      "63/63 [==============================] - 0s 949us/step - loss: 0.0317 - accuracy: 0.0000e+00\n",
      "Epoch 189/300\n",
      "63/63 [==============================] - 0s 881us/step - loss: 0.0320 - accuracy: 0.0000e+00\n",
      "Epoch 190/300\n",
      "63/63 [==============================] - 0s 925us/step - loss: 0.0316 - accuracy: 0.0000e+00\n",
      "Epoch 191/300\n",
      "63/63 [==============================] - 0s 942us/step - loss: 0.0343 - accuracy: 0.0000e+00\n",
      "Epoch 192/300\n",
      "63/63 [==============================] - 0s 971us/step - loss: 0.0274 - accuracy: 0.0000e+00\n",
      "Epoch 193/300\n",
      "63/63 [==============================] - 0s 916us/step - loss: 0.0321 - accuracy: 0.0000e+00\n",
      "Epoch 194/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 0.0300 - accuracy: 0.0000e+00\n",
      "Epoch 195/300\n",
      "63/63 [==============================] - 0s 804us/step - loss: 0.0342 - accuracy: 0.0000e+00\n",
      "Epoch 196/300\n",
      "63/63 [==============================] - 0s 942us/step - loss: 0.0296 - accuracy: 0.0000e+00\n",
      "Epoch 197/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 0.0301 - accuracy: 0.0000e+00\n",
      "Epoch 198/300\n",
      "63/63 [==============================] - 0s 950us/step - loss: 0.0344 - accuracy: 0.0000e+00\n",
      "Epoch 199/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.0000e+00\n",
      "Epoch 200/300\n",
      "63/63 [==============================] - 0s 869us/step - loss: 0.0307 - accuracy: 0.0000e+00\n",
      "Epoch 201/300\n",
      "63/63 [==============================] - 0s 845us/step - loss: 0.0351 - accuracy: 0.0000e+00\n",
      "Epoch 202/300\n",
      "63/63 [==============================] - 0s 869us/step - loss: 0.0315 - accuracy: 0.0000e+00\n",
      "Epoch 203/300\n",
      "63/63 [==============================] - 0s 973us/step - loss: 0.0296 - accuracy: 0.0000e+00\n",
      "Epoch 204/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.0000e+00\n",
      "Epoch 205/300\n",
      "63/63 [==============================] - 0s 885us/step - loss: 0.0291 - accuracy: 0.0000e+00\n",
      "Epoch 206/300\n",
      "63/63 [==============================] - 0s 898us/step - loss: 0.0320 - accuracy: 0.0000e+00\n",
      "Epoch 207/300\n",
      "63/63 [==============================] - 0s 941us/step - loss: 0.0310 - accuracy: 0.0000e+00\n",
      "Epoch 208/300\n",
      "63/63 [==============================] - 0s 997us/step - loss: 0.0312 - accuracy: 0.0000e+00\n",
      "Epoch 209/300\n",
      "63/63 [==============================] - 0s 925us/step - loss: 0.0296 - accuracy: 0.0000e+00\n",
      "Epoch 210/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.0000e+00\n",
      "Epoch 211/300\n",
      "63/63 [==============================] - 0s 877us/step - loss: 0.0347 - accuracy: 0.0000e+00\n",
      "Epoch 212/300\n",
      "63/63 [==============================] - 0s 969us/step - loss: 0.0319 - accuracy: 0.0000e+00\n",
      "Epoch 213/300\n",
      "63/63 [==============================] - 0s 922us/step - loss: 0.0295 - accuracy: 0.0000e+00\n",
      "Epoch 214/300\n",
      "63/63 [==============================] - 0s 985us/step - loss: 0.0306 - accuracy: 0.0000e+00\n",
      "Epoch 215/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.0000e+00\n",
      "Epoch 216/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 0.0258 - accuracy: 0.0000e+00\n",
      "Epoch 217/300\n",
      "63/63 [==============================] - 0s 943us/step - loss: 0.0322 - accuracy: 0.0000e+00\n",
      "Epoch 218/300\n",
      "63/63 [==============================] - 0s 949us/step - loss: 0.0318 - accuracy: 0.0000e+00\n",
      "Epoch 219/300\n",
      "63/63 [==============================] - 0s 925us/step - loss: 0.0303 - accuracy: 0.0000e+00\n",
      "Epoch 220/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.0000e+00\n",
      "Epoch 221/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.0000e+00\n",
      "Epoch 222/300\n",
      "63/63 [==============================] - 0s 901us/step - loss: 0.0287 - accuracy: 0.0000e+00\n",
      "Epoch 223/300\n",
      "63/63 [==============================] - 0s 953us/step - loss: 0.0341 - accuracy: 0.0000e+00\n",
      "Epoch 224/300\n",
      "63/63 [==============================] - 0s 928us/step - loss: 0.0308 - accuracy: 0.0000e+00\n",
      "Epoch 225/300\n",
      "63/63 [==============================] - 0s 912us/step - loss: 0.0294 - accuracy: 0.0000e+00\n",
      "Epoch 226/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.0000e+00\n",
      "Epoch 227/300\n",
      "63/63 [==============================] - 0s 981us/step - loss: 0.0311 - accuracy: 0.0000e+00\n",
      "Epoch 228/300\n",
      "63/63 [==============================] - 0s 941us/step - loss: 0.0345 - accuracy: 0.0000e+00\n",
      "Epoch 229/300\n",
      "63/63 [==============================] - 0s 926us/step - loss: 0.0261 - accuracy: 0.0000e+00\n",
      "Epoch 230/300\n",
      "63/63 [==============================] - 0s 958us/step - loss: 0.0328 - accuracy: 0.0000e+00\n",
      "Epoch 231/300\n",
      "63/63 [==============================] - 0s 925us/step - loss: 0.0330 - accuracy: 0.0000e+00\n",
      "Epoch 232/300\n",
      "63/63 [==============================] - 0s 854us/step - loss: 0.0324 - accuracy: 0.0000e+00\n",
      "Epoch 233/300\n",
      "63/63 [==============================] - 0s 844us/step - loss: 0.0292 - accuracy: 0.0000e+00\n",
      "Epoch 234/300\n",
      "63/63 [==============================] - 0s 935us/step - loss: 0.0288 - accuracy: 0.0000e+00\n",
      "Epoch 235/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.0000e+00\n",
      "Epoch 236/300\n",
      "63/63 [==============================] - 0s 990us/step - loss: 0.0337 - accuracy: 0.0000e+00\n",
      "Epoch 237/300\n",
      "63/63 [==============================] - 0s 933us/step - loss: 0.0281 - accuracy: 0.0000e+00\n",
      "Epoch 238/300\n",
      "63/63 [==============================] - 0s 908us/step - loss: 0.0337 - accuracy: 0.0000e+00\n",
      "Epoch 239/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.0000e+00\n",
      "Epoch 240/300\n",
      "63/63 [==============================] - 0s 878us/step - loss: 0.0272 - accuracy: 0.0000e+00\n",
      "Epoch 241/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.0000e+00\n",
      "Epoch 242/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.0000e+00\n",
      "Epoch 243/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 0.0260 - accuracy: 0.0000e+00\n",
      "Epoch 244/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.0000e+00\n",
      "Epoch 245/300\n",
      "63/63 [==============================] - 0s 877us/step - loss: 0.0287 - accuracy: 0.0000e+00\n",
      "Epoch 246/300\n",
      "63/63 [==============================] - 0s 901us/step - loss: 0.0317 - accuracy: 0.0000e+00\n",
      "Epoch 247/300\n",
      "63/63 [==============================] - 0s 877us/step - loss: 0.0321 - accuracy: 0.0000e+00\n",
      "Epoch 248/300\n",
      "63/63 [==============================] - 0s 973us/step - loss: 0.0339 - accuracy: 0.0000e+00\n",
      "Epoch 249/300\n",
      "63/63 [==============================] - 0s 901us/step - loss: 0.0278 - accuracy: 0.0000e+00\n",
      "Epoch 250/300\n",
      "63/63 [==============================] - 0s 877us/step - loss: 0.0309 - accuracy: 0.0000e+00\n",
      "Epoch 251/300\n",
      "63/63 [==============================] - 0s 956us/step - loss: 0.0365 - accuracy: 0.0000e+00\n",
      "Epoch 252/300\n",
      "63/63 [==============================] - 0s 990us/step - loss: 0.0291 - accuracy: 0.0000e+00\n",
      "Epoch 253/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.0000e+00\n",
      "Epoch 254/300\n",
      "63/63 [==============================] - 0s 962us/step - loss: 0.0315 - accuracy: 0.0000e+00\n",
      "Epoch 255/300\n",
      "63/63 [==============================] - 0s 924us/step - loss: 0.0329 - accuracy: 0.0000e+00\n",
      "Epoch 256/300\n",
      "63/63 [==============================] - 0s 906us/step - loss: 0.0333 - accuracy: 0.0000e+00\n",
      "Epoch 257/300\n",
      "63/63 [==============================] - 0s 870us/step - loss: 0.0252 - accuracy: 0.0000e+00\n",
      "Epoch 258/300\n",
      "63/63 [==============================] - 0s 887us/step - loss: 0.0366 - accuracy: 0.0000e+00\n",
      "Epoch 259/300\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.0000e+00\n",
      "Epoch 260/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 0.0308 - accuracy: 0.0000e+00\n",
      "Epoch 261/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.0000e+00\n",
      "Epoch 262/300\n",
      "63/63 [==============================] - 0s 954us/step - loss: 0.0283 - accuracy: 0.0000e+00\n",
      "Epoch 263/300\n",
      "63/63 [==============================] - 0s 901us/step - loss: 0.0336 - accuracy: 0.0000e+00\n",
      "Epoch 264/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.0000e+00\n",
      "Epoch 265/300\n",
      "63/63 [==============================] - 0s 925us/step - loss: 0.0344 - accuracy: 0.0000e+00\n",
      "Epoch 266/300\n",
      "63/63 [==============================] - 0s 906us/step - loss: 0.0328 - accuracy: 0.0000e+00\n",
      "Epoch 267/300\n",
      "63/63 [==============================] - 0s 856us/step - loss: 0.0308 - accuracy: 0.0000e+00\n",
      "Epoch 268/300\n",
      "63/63 [==============================] - 0s 840us/step - loss: 0.0301 - accuracy: 0.0000e+00\n",
      "Epoch 269/300\n",
      "63/63 [==============================] - 0s 999us/step - loss: 0.0319 - accuracy: 0.0000e+00\n",
      "Epoch 270/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.0000e+00\n",
      "Epoch 271/300\n",
      "63/63 [==============================] - 0s 933us/step - loss: 0.0301 - accuracy: 0.0000e+00\n",
      "Epoch 272/300\n",
      "63/63 [==============================] - 0s 997us/step - loss: 0.0364 - accuracy: 0.0000e+00\n",
      "Epoch 273/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.0000e+00\n",
      "Epoch 274/300\n",
      "63/63 [==============================] - 0s 981us/step - loss: 0.0355 - accuracy: 0.0000e+00\n",
      "Epoch 275/300\n",
      "63/63 [==============================] - 0s 981us/step - loss: 0.0258 - accuracy: 0.0000e+00\n",
      "Epoch 276/300\n",
      "63/63 [==============================] - 0s 949us/step - loss: 0.0299 - accuracy: 0.0000e+00\n",
      "Epoch 277/300\n",
      "63/63 [==============================] - 0s 885us/step - loss: 0.0339 - accuracy: 0.0000e+00\n",
      "Epoch 278/300\n",
      "63/63 [==============================] - 0s 861us/step - loss: 0.0297 - accuracy: 0.0000e+00\n",
      "Epoch 279/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.0000e+00\n",
      "Epoch 280/300\n",
      "63/63 [==============================] - 0s 997us/step - loss: 0.0285 - accuracy: 0.0000e+00\n",
      "Epoch 281/300\n",
      "63/63 [==============================] - 0s 941us/step - loss: 0.0335 - accuracy: 0.0000e+00\n",
      "Epoch 282/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.0000e+00\n",
      "Epoch 283/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.0000e+00\n",
      "Epoch 284/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.0000e+00\n",
      "Epoch 285/300\n",
      "63/63 [==============================] - 0s 988us/step - loss: 0.0325 - accuracy: 0.0000e+00\n",
      "Epoch 286/300\n",
      "63/63 [==============================] - 0s 940us/step - loss: 0.0303 - accuracy: 0.0000e+00\n",
      "Epoch 287/300\n",
      "63/63 [==============================] - 0s 949us/step - loss: 0.0282 - accuracy: 0.0000e+00\n",
      "Epoch 288/300\n",
      "63/63 [==============================] - 0s 973us/step - loss: 0.0344 - accuracy: 0.0000e+00\n",
      "Epoch 289/300\n",
      "63/63 [==============================] - 0s 820us/step - loss: 0.0319 - accuracy: 0.0000e+00\n",
      "Epoch 290/300\n",
      "63/63 [==============================] - 0s 936us/step - loss: 0.0289 - accuracy: 0.0000e+00\n",
      "Epoch 291/300\n",
      "63/63 [==============================] - 0s 889us/step - loss: 0.0341 - accuracy: 0.0000e+00\n",
      "Epoch 292/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.0000e+00\n",
      "Epoch 293/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.0000e+00\n",
      "Epoch 294/300\n",
      "63/63 [==============================] - 0s 909us/step - loss: 0.0333 - accuracy: 0.0000e+00\n",
      "Epoch 295/300\n",
      "63/63 [==============================] - 0s 885us/step - loss: 0.0322 - accuracy: 0.0000e+00\n",
      "Epoch 296/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.0000e+00\n",
      "Epoch 297/300\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.0000e+00\n",
      "Epoch 298/300\n",
      "63/63 [==============================] - 0s 917us/step - loss: 0.0283 - accuracy: 0.0000e+00\n",
      "Epoch 299/300\n",
      "63/63 [==============================] - 0s 925us/step - loss: 0.0308 - accuracy: 0.0000e+00\n",
      "Epoch 300/300\n",
      "63/63 [==============================] - 0s 965us/step - loss: 0.0306 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ee12f51c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_model.fit(train_X,train_y, epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 771us/step\n"
     ]
    }
   ],
   "source": [
    "model_output = digit_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.zeros(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [-225.63448] vs Actual Value: -225.4\n",
      "Predicted Value: [39.204735] vs Actual Value: 39.2\n",
      "Predicted Value: [30.196598] vs Actual Value: 30.2\n",
      "Predicted Value: [260.8049] vs Actual Value: 260.6\n",
      "Predicted Value: [127.484474] vs Actual Value: 127.4\n",
      "Predicted Value: [24.791718] vs Actual Value: 24.8\n",
      "Predicted Value: [71.63403] vs Actual Value: 71.6\n",
      "Predicted Value: [-261.66702] vs Actual Value: -261.4\n",
      "Predicted Value: [132.88936] vs Actual Value: 132.8\n",
      "Predicted Value: [-50.87663] vs Actual Value: -50.8\n",
      "Predicted Value: [80.642166] vs Actual Value: 80.6\n",
      "Predicted Value: [271.6147] vs Actual Value: 271.4\n",
      "Predicted Value: [31.998226] vs Actual Value: 32.0\n",
      "Predicted Value: [-124.74336] vs Actual Value: -124.6\n",
      "Predicted Value: [-43.67012] vs Actual Value: -43.6\n",
      "Predicted Value: [168.9219] vs Actual Value: 168.8\n",
      "Predicted Value: [39.204735] vs Actual Value: 39.2\n",
      "Predicted Value: [-263.46866] vs Actual Value: -263.2\n",
      "Predicted Value: [277.01956] vs Actual Value: 276.8\n",
      "Predicted Value: [300.44073] vs Actual Value: 300.2\n",
      "Predicted Value: [-72.49616] vs Actual Value: -72.4\n",
      "Predicted Value: [-101.322205] vs Actual Value: -101.2\n",
      "Predicted Value: [122.0796] vs Actual Value: 122.0\n",
      "Predicted Value: [-38.26524] vs Actual Value: -38.2\n",
      "Predicted Value: [80.642166] vs Actual Value: 80.6\n",
      "Predicted Value: [-7.637576] vs Actual Value: -7.6\n",
      "Predicted Value: [17.585207] vs Actual Value: 17.6\n",
      "Predicted Value: [107.66658] vs Actual Value: 107.6\n",
      "Predicted Value: [293.23422] vs Actual Value: 293.0\n",
      "Predicted Value: [277.01956] vs Actual Value: 276.8\n",
      "Predicted Value: [-160.7759] vs Actual Value: -160.6\n",
      "Predicted Value: [-236.44426] vs Actual Value: -236.2\n",
      "Predicted Value: [192.34306] vs Actual Value: 192.2\n",
      "Predicted Value: [-245.4524] vs Actual Value: -245.2\n",
      "Predicted Value: [68.03078] vs Actual Value: 68.0\n",
      "Predicted Value: [253.59839] vs Actual Value: 253.4\n",
      "Predicted Value: [71.63403] vs Actual Value: 71.6\n",
      "Predicted Value: [-103.123825] vs Actual Value: -103.0\n",
      "Predicted Value: [-104.92545] vs Actual Value: -104.8\n",
      "Predicted Value: [-36.463615] vs Actual Value: -36.4\n",
      "Predicted Value: [203.15282] vs Actual Value: 203.0\n",
      "Predicted Value: [-34.661987] vs Actual Value: -34.6\n",
      "Predicted Value: [260.8049] vs Actual Value: 260.6\n",
      "Predicted Value: [-286.88983] vs Actual Value: -286.6\n",
      "Predicted Value: [24.791718] vs Actual Value: 24.8\n",
      "Predicted Value: [17.585207] vs Actual Value: 17.6\n",
      "Predicted Value: [293.23422] vs Actual Value: 293.0\n",
      "Predicted Value: [30.196598] vs Actual Value: 30.2\n",
      "Predicted Value: [-36.463615] vs Actual Value: -36.4\n",
      "Predicted Value: [-301.30283] vs Actual Value: -301.0\n",
      "Predicted Value: [-211.22147] vs Actual Value: -211.0\n",
      "Predicted Value: [221.16911] vs Actual Value: 221.0\n",
      "Predicted Value: [156.31052] vs Actual Value: 156.2\n",
      "Predicted Value: [31.998226] vs Actual Value: 32.0\n",
      "Predicted Value: [289.63095] vs Actual Value: 289.4\n",
      "Predicted Value: [199.54956] vs Actual Value: 199.4\n",
      "Predicted Value: [-191.40356] vs Actual Value: -191.2\n",
      "Predicted Value: [-121.14011] vs Actual Value: -121.0\n",
      "Predicted Value: [22.99009] vs Actual Value: 23.0\n",
      "Predicted Value: [-259.8654] vs Actual Value: -259.6\n",
      "Predicted Value: [-67.09128] vs Actual Value: -67.0\n",
      "Predicted Value: [118.47634] vs Actual Value: 118.4\n",
      "Predicted Value: [78.84054] vs Actual Value: 78.8\n",
      "Predicted Value: [-16.645714] vs Actual Value: -16.6\n",
      "Predicted Value: [-97.71895] vs Actual Value: -97.6\n",
      "Predicted Value: [-249.05565] vs Actual Value: -248.8\n",
      "Predicted Value: [-135.55312] vs Actual Value: -135.4\n",
      "Predicted Value: [8.57707] vs Actual Value: 8.6\n",
      "Predicted Value: [-185.9987] vs Actual Value: -185.8\n",
      "Predicted Value: [-36.463615] vs Actual Value: -36.4\n",
      "Predicted Value: [131.08774] vs Actual Value: 131.0\n",
      "Predicted Value: [167.12029] vs Actual Value: 167.0\n",
      "Predicted Value: [118.47634] vs Actual Value: 118.4\n",
      "Predicted Value: [181.5333] vs Actual Value: 181.4\n",
      "Predicted Value: [24.791718] vs Actual Value: 24.8\n",
      "Predicted Value: [93.253555] vs Actual Value: 93.2\n",
      "Predicted Value: [-249.05565] vs Actual Value: -248.8\n",
      "Predicted Value: [-81.5043] vs Actual Value: -81.4\n",
      "Predicted Value: [-49.075005] vs Actual Value: -49.0\n",
      "Predicted Value: [-288.69144] vs Actual Value: -288.4\n",
      "Predicted Value: [186.93819] vs Actual Value: 186.8\n",
      "Predicted Value: [136.49261] vs Actual Value: 136.4\n",
      "Predicted Value: [-292.29468] vs Actual Value: -292.0\n",
      "Predicted Value: [268.0114] vs Actual Value: 267.8\n",
      "Predicted Value: [194.14468] vs Actual Value: 194.0\n",
      "Predicted Value: [195.9463] vs Actual Value: 195.8\n",
      "Predicted Value: [259.0033] vs Actual Value: 258.8\n",
      "Predicted Value: [302.24234] vs Actual Value: 302.0\n",
      "Predicted Value: [-18.447342] vs Actual Value: -18.4\n",
      "Predicted Value: [-205.81659] vs Actual Value: -205.6\n",
      "Predicted Value: [222.97073] vs Actual Value: 222.8\n",
      "Predicted Value: [39.204735] vs Actual Value: 39.2\n",
      "Predicted Value: [8.57707] vs Actual Value: 8.6\n",
      "Predicted Value: [71.63403] vs Actual Value: 71.6\n",
      "Predicted Value: [-243.65077] vs Actual Value: -243.4\n",
      "Predicted Value: [-128.34662] vs Actual Value: -128.2\n",
      "Predicted Value: [69.832405] vs Actual Value: 69.8\n",
      "Predicted Value: [-207.61823] vs Actual Value: -207.4\n",
      "Predicted Value: [239.18536] vs Actual Value: 239.0\n",
      "Predicted Value: [248.19351] vs Actual Value: 248.0\n",
      "Predicted Value: [82.443794] vs Actual Value: 82.4\n",
      "Predicted Value: [-319.3191] vs Actual Value: -319.0\n",
      "Predicted Value: [159.91377] vs Actual Value: 159.8\n",
      "Predicted Value: [145.50075] vs Actual Value: 145.4\n",
      "Predicted Value: [145.50075] vs Actual Value: 145.4\n",
      "Predicted Value: [210.35933] vs Actual Value: 210.2\n",
      "Predicted Value: [197.74794] vs Actual Value: 197.6\n",
      "Predicted Value: [278.8212] vs Actual Value: 278.6\n",
      "Predicted Value: [-216.62636] vs Actual Value: -216.4\n",
      "Predicted Value: [26.593346] vs Actual Value: 26.6\n",
      "Predicted Value: [-277.88168] vs Actual Value: -277.6\n",
      "Predicted Value: [-72.49616] vs Actual Value: -72.4\n",
      "Predicted Value: [-148.16452] vs Actual Value: -148.0\n",
      "Predicted Value: [-182.39542] vs Actual Value: -182.2\n",
      "Predicted Value: [75.23728] vs Actual Value: 75.2\n",
      "Predicted Value: [-187.80031] vs Actual Value: -187.6\n",
      "Predicted Value: [-29.257103] vs Actual Value: -29.2\n",
      "Predicted Value: [62.625896] vs Actual Value: 62.6\n",
      "Predicted Value: [109.4682] vs Actual Value: 109.4\n",
      "Predicted Value: [-315.71585] vs Actual Value: -315.4\n",
      "Predicted Value: [-7.637576] vs Actual Value: -7.6\n",
      "Predicted Value: [-225.63448] vs Actual Value: -225.4\n",
      "Predicted Value: [-45.47175] vs Actual Value: -45.4\n",
      "Predicted Value: [266.2098] vs Actual Value: 266.0\n",
      "Predicted Value: [93.253555] vs Actual Value: 93.2\n",
      "Predicted Value: [251.79677] vs Actual Value: 251.6\n",
      "Predicted Value: [275.21793] vs Actual Value: 275.0\n",
      "Predicted Value: [-140.95801] vs Actual Value: -140.8\n",
      "Predicted Value: [-86.90918] vs Actual Value: -86.8\n",
      "Predicted Value: [168.9219] vs Actual Value: 168.8\n",
      "Predicted Value: [181.5333] vs Actual Value: 181.4\n",
      "Predicted Value: [147.30238] vs Actual Value: 147.2\n",
      "Predicted Value: [221.16911] vs Actual Value: 221.0\n",
      "Predicted Value: [-182.39542] vs Actual Value: -182.2\n",
      "Predicted Value: [219.36748] vs Actual Value: 219.2\n",
      "Predicted Value: [158.11214] vs Actual Value: 158.0\n",
      "Predicted Value: [109.4682] vs Actual Value: 109.4\n",
      "Predicted Value: [-222.03125] vs Actual Value: -221.8\n",
      "Predicted Value: [104.063324] vs Actual Value: 104.0\n",
      "Predicted Value: [-142.75963] vs Actual Value: -142.6\n",
      "Predicted Value: [278.8212] vs Actual Value: 278.6\n",
      "Predicted Value: [-126.54498] vs Actual Value: -126.4\n",
      "Predicted Value: [-184.19707] vs Actual Value: -184.0\n",
      "Predicted Value: [98.65844] vs Actual Value: 98.6\n",
      "Predicted Value: [42.80799] vs Actual Value: 42.8\n",
      "Predicted Value: [-94.11569] vs Actual Value: -94.0\n",
      "Predicted Value: [91.45193] vs Actual Value: 91.4\n",
      "Predicted Value: [206.75607] vs Actual Value: 206.6\n",
      "Predicted Value: [277.01956] vs Actual Value: 276.8\n",
      "Predicted Value: [251.79677] vs Actual Value: 251.6\n",
      "Predicted Value: [39.204735] vs Actual Value: 39.2\n",
      "Predicted Value: [-202.21333] vs Actual Value: -202.0\n",
      "Predicted Value: [12.180325] vs Actual Value: 12.2\n",
      "Predicted Value: [-229.23776] vs Actual Value: -229.0\n",
      "Predicted Value: [-229.23776] vs Actual Value: -229.0\n",
      "Predicted Value: [62.625896] vs Actual Value: 62.6\n",
      "Predicted Value: [-90.512436] vs Actual Value: -90.4\n",
      "Predicted Value: [96.85681] vs Actual Value: 96.8\n",
      "Predicted Value: [212.16096] vs Actual Value: 212.0\n",
      "Predicted Value: [30.196598] vs Actual Value: 30.2\n",
      "Predicted Value: [-86.90918] vs Actual Value: -86.8\n",
      "Predicted Value: [-106.72708] vs Actual Value: -106.6\n",
      "Predicted Value: [275.21793] vs Actual Value: 275.0\n",
      "Predicted Value: [-209.41985] vs Actual Value: -209.2\n",
      "Predicted Value: [-254.46053] vs Actual Value: -254.2\n",
      "Predicted Value: [-95.91732] vs Actual Value: -95.8\n",
      "Predicted Value: [278.8212] vs Actual Value: 278.6\n",
      "Predicted Value: [-86.90918] vs Actual Value: -86.8\n",
      "Predicted Value: [-167.9824] vs Actual Value: -167.8\n",
      "Predicted Value: [136.49261] vs Actual Value: 136.4\n",
      "Predicted Value: [-56.281513] vs Actual Value: -56.2\n",
      "Predicted Value: [-176.99055] vs Actual Value: -176.8\n",
      "Predicted Value: [-272.4768] vs Actual Value: -272.2\n",
      "Predicted Value: [-59.88477] vs Actual Value: -59.8\n",
      "Predicted Value: [21.188461] vs Actual Value: 21.2\n",
      "Predicted Value: [-16.645714] vs Actual Value: -16.6\n",
      "Predicted Value: [-202.21333] vs Actual Value: -202.0\n",
      "Predicted Value: [35.601482] vs Actual Value: 35.6\n",
      "Predicted Value: [116.67471] vs Actual Value: 116.6\n",
      "Predicted Value: [-214.82474] vs Actual Value: -214.6\n",
      "Predicted Value: [-162.57753] vs Actual Value: -162.4\n",
      "Predicted Value: [-27.455479] vs Actual Value: -27.4\n",
      "Predicted Value: [-94.11569] vs Actual Value: -94.0\n",
      "Predicted Value: [-128.34662] vs Actual Value: -128.2\n",
      "Predicted Value: [199.54956] vs Actual Value: 199.4\n",
      "Predicted Value: [-43.67012] vs Actual Value: -43.6\n",
      "Predicted Value: [-220.22961] vs Actual Value: -220.0\n",
      "Predicted Value: [-7.637576] vs Actual Value: -7.6\n",
      "Predicted Value: [280.62283] vs Actual Value: 280.4\n",
      "Predicted Value: [60.82427] vs Actual Value: 60.8\n",
      "Predicted Value: [-301.30283] vs Actual Value: -301.0\n",
      "Predicted Value: [-18.447342] vs Actual Value: -18.4\n",
      "Predicted Value: [-189.60193] vs Actual Value: -189.4\n",
      "Predicted Value: [201.3512] vs Actual Value: 201.2\n",
      "Predicted Value: [302.24234] vs Actual Value: 302.0\n",
      "Predicted Value: [80.642166] vs Actual Value: 80.6\n",
      "Predicted Value: [95.05518] vs Actual Value: 95.0\n",
      "Predicted Value: [259.0033] vs Actual Value: 258.8\n",
      "Predicted Value: [208.55771] vs Actual Value: 208.4\n",
      "Predicted Value: [152.70726] vs Actual Value: 152.6\n",
      "Predicted Value: [75.23728] vs Actual Value: 75.2\n",
      "Predicted Value: [26.593346] vs Actual Value: 26.6\n",
      "Predicted Value: [273.41632] vs Actual Value: 273.2\n",
      "Predicted Value: [-238.24588] vs Actual Value: -238.0\n",
      "Predicted Value: [-140.95801] vs Actual Value: -140.8\n",
      "Predicted Value: [-142.75963] vs Actual Value: -142.6\n",
      "Predicted Value: [102.261696] vs Actual Value: 102.2\n",
      "Predicted Value: [68.03078] vs Actual Value: 68.0\n",
      "Predicted Value: [-106.72708] vs Actual Value: -106.6\n",
      "Predicted Value: [-151.76776] vs Actual Value: -151.6\n",
      "Predicted Value: [-265.2703] vs Actual Value: -265.0\n",
      "Predicted Value: [-95.91732] vs Actual Value: -95.8\n",
      "Predicted Value: [271.6147] vs Actual Value: 271.4\n",
      "Predicted Value: [-76.09942] vs Actual Value: -76.0\n",
      "Predicted Value: [-164.37917] vs Actual Value: -164.2\n",
      "Predicted Value: [-193.20522] vs Actual Value: -193.0\n",
      "Predicted Value: [35.601482] vs Actual Value: 35.6\n",
      "Predicted Value: [-218.42796] vs Actual Value: -218.2\n",
      "Predicted Value: [-301.30283] vs Actual Value: -301.0\n",
      "Predicted Value: [-135.55312] vs Actual Value: -135.4\n",
      "Predicted Value: [-101.322205] vs Actual Value: -101.2\n",
      "Predicted Value: [-110.33034] vs Actual Value: -110.2\n",
      "Predicted Value: [-164.37917] vs Actual Value: -164.2\n",
      "Predicted Value: [170.72354] vs Actual Value: 170.6\n",
      "Predicted Value: [-157.17267] vs Actual Value: -157.0\n",
      "Predicted Value: [-250.85728] vs Actual Value: -250.6\n",
      "Predicted Value: [24.791718] vs Actual Value: 24.8\n",
      "Predicted Value: [24.791718] vs Actual Value: 24.8\n",
      "Predicted Value: [-124.74336] vs Actual Value: -124.6\n",
      "Predicted Value: [-238.24588] vs Actual Value: -238.0\n",
      "Predicted Value: [277.01956] vs Actual Value: 276.8\n",
      "Predicted Value: [-65.28965] vs Actual Value: -65.2\n",
      "Predicted Value: [-162.57753] vs Actual Value: -162.4\n",
      "Predicted Value: [298.6391] vs Actual Value: 298.4\n",
      "Predicted Value: [165.31865] vs Actual Value: 165.2\n",
      "Predicted Value: [188.7398] vs Actual Value: 188.6\n",
      "Predicted Value: [-218.42796] vs Actual Value: -218.2\n",
      "Predicted Value: [199.54956] vs Actual Value: 199.4\n",
      "Predicted Value: [93.253555] vs Actual Value: 93.2\n",
      "Predicted Value: [-106.72708] vs Actual Value: -106.6\n",
      "Predicted Value: [295.03583] vs Actual Value: 294.8\n",
      "Predicted Value: [100.46007] vs Actual Value: 100.4\n",
      "Predicted Value: [84.24542] vs Actual Value: 84.2\n",
      "Predicted Value: [-222.03125] vs Actual Value: -221.8\n",
      "Predicted Value: [-211.22147] vs Actual Value: -211.0\n",
      "Predicted Value: [-124.74336] vs Actual Value: -124.6\n",
      "Predicted Value: [-231.03937] vs Actual Value: -230.8\n",
      "Predicted Value: [-180.59381] vs Actual Value: -180.4\n",
      "Predicted Value: [161.7154] vs Actual Value: 161.6\n",
      "Predicted Value: [-90.512436] vs Actual Value: -90.4\n",
      "Predicted Value: [-142.75963] vs Actual Value: -142.6\n",
      "Predicted Value: [-254.46053] vs Actual Value: -254.2\n",
      "Predicted Value: [240.987] vs Actual Value: 240.8\n",
      "Predicted Value: [-187.80031] vs Actual Value: -187.6\n",
      "Predicted Value: [68.03078] vs Actual Value: 68.0\n",
      "Predicted Value: [-259.8654] vs Actual Value: -259.6\n",
      "Predicted Value: [-258.06378] vs Actual Value: -257.8\n",
      "Predicted Value: [-204.01495] vs Actual Value: -203.8\n",
      "Predicted Value: [-171.58568] vs Actual Value: -171.4\n",
      "Predicted Value: [-122.94173] vs Actual Value: -122.8\n",
      "Predicted Value: [-29.257103] vs Actual Value: -29.2\n",
      "Predicted Value: [-292.29468] vs Actual Value: -292.0\n",
      "Predicted Value: [302.24234] vs Actual Value: 302.0\n",
      "Predicted Value: [296.83746] vs Actual Value: 296.6\n",
      "Predicted Value: [-328.32724] vs Actual Value: -328.0\n",
      "Predicted Value: [192.34306] vs Actual Value: 192.2\n",
      "Predicted Value: [217.56584] vs Actual Value: 217.4\n",
      "Predicted Value: [-61.686398] vs Actual Value: -61.6\n",
      "Predicted Value: [132.88936] vs Actual Value: 132.8\n",
      "Predicted Value: [-187.80031] vs Actual Value: -187.6\n",
      "Predicted Value: [50.0145] vs Actual Value: 50.0\n",
      "Predicted Value: [-272.4768] vs Actual Value: -272.2\n",
      "Predicted Value: [-187.80031] vs Actual Value: -187.6\n",
      "Predicted Value: [64.42752] vs Actual Value: 64.4\n",
      "Predicted Value: [197.74794] vs Actual Value: 197.6\n",
      "Predicted Value: [-211.22147] vs Actual Value: -211.0\n",
      "Predicted Value: [-328.32724] vs Actual Value: -328.0\n",
      "Predicted Value: [-286.88983] vs Actual Value: -286.6\n",
      "Predicted Value: [19.386833] vs Actual Value: 19.4\n",
      "Predicted Value: [-295.89795] vs Actual Value: -295.6\n",
      "Predicted Value: [-189.60193] vs Actual Value: -189.4\n",
      "Predicted Value: [194.14468] vs Actual Value: 194.0\n",
      "Predicted Value: [302.24234] vs Actual Value: 302.0\n",
      "Predicted Value: [10.378697] vs Actual Value: 10.4\n",
      "Predicted Value: [3.1721878] vs Actual Value: 3.2\n",
      "Predicted Value: [89.6503] vs Actual Value: 89.6\n",
      "Predicted Value: [-20.24897] vs Actual Value: -20.2\n",
      "Predicted Value: [4.973815] vs Actual Value: 5.0\n",
      "Predicted Value: [-88.71081] vs Actual Value: -88.6\n",
      "Predicted Value: [-294.0963] vs Actual Value: -293.8\n",
      "Predicted Value: [57.221012] vs Actual Value: 57.2\n",
      "Predicted Value: [-162.57753] vs Actual Value: -162.4\n",
      "Predicted Value: [273.41632] vs Actual Value: 273.2\n",
      "Predicted Value: [147.30238] vs Actual Value: 147.2\n",
      "Predicted Value: [-180.59381] vs Actual Value: -180.4\n",
      "Predicted Value: [233.78049] vs Actual Value: 233.6\n",
      "Predicted Value: [-38.26524] vs Actual Value: -38.2\n",
      "Predicted Value: [-202.21333] vs Actual Value: -202.0\n",
      "Predicted Value: [-272.4768] vs Actual Value: -272.2\n",
      "Predicted Value: [-2.2326946] vs Actual Value: -2.2\n",
      "Predicted Value: [262.60654] vs Actual Value: 262.4\n",
      "Predicted Value: [242.78864] vs Actual Value: 242.6\n",
      "Predicted Value: [-148.16452] vs Actual Value: -148.0\n",
      "Predicted Value: [-243.65077] vs Actual Value: -243.4\n",
      "Predicted Value: [-40.066864] vs Actual Value: -40.0\n",
      "Predicted Value: [-4.034322] vs Actual Value: -4.0\n",
      "Predicted Value: [230.17725] vs Actual Value: 230.0\n",
      "Predicted Value: [132.88936] vs Actual Value: 132.8\n",
      "Predicted Value: [-234.64262] vs Actual Value: -234.4\n",
      "Predicted Value: [201.3512] vs Actual Value: 201.2\n",
      "Predicted Value: [286.0277] vs Actual Value: 285.8\n",
      "Predicted Value: [-294.0963] vs Actual Value: -293.8\n",
      "Predicted Value: [159.91377] vs Actual Value: 159.8\n",
      "Predicted Value: [224.77234] vs Actual Value: 224.6\n",
      "Predicted Value: [-312.11258] vs Actual Value: -311.8\n",
      "Predicted Value: [-72.49616] vs Actual Value: -72.4\n",
      "Predicted Value: [138.29424] vs Actual Value: 138.2\n",
      "Predicted Value: [78.84054] vs Actual Value: 78.8\n",
      "Predicted Value: [19.386833] vs Actual Value: 19.4\n",
      "Predicted Value: [-72.49616] vs Actual Value: -72.4\n",
      "Predicted Value: [-103.123825] vs Actual Value: -103.0\n",
      "Predicted Value: [231.97885] vs Actual Value: 231.8\n",
      "Predicted Value: [57.221012] vs Actual Value: 57.2\n",
      "Predicted Value: [-9.439204] vs Actual Value: -9.4\n",
      "Predicted Value: [-65.28965] vs Actual Value: -65.2\n",
      "Predicted Value: [28.39497] vs Actual Value: 28.4\n",
      "Predicted Value: [10.378697] vs Actual Value: 10.4\n",
      "Predicted Value: [-321.12073] vs Actual Value: -320.8\n",
      "Predicted Value: [-277.88168] vs Actual Value: -277.6\n",
      "Predicted Value: [-306.7077] vs Actual Value: -306.4\n",
      "Predicted Value: [125.68285] vs Actual Value: 125.6\n",
      "Predicted Value: [-272.4768] vs Actual Value: -272.2\n",
      "Predicted Value: [-68.89291] vs Actual Value: -68.8\n",
      "Predicted Value: [129.2861] vs Actual Value: 129.2\n",
      "Predicted Value: [-286.88983] vs Actual Value: -286.6\n",
      "Predicted Value: [-126.54498] vs Actual Value: -126.4\n",
      "Predicted Value: [190.54144] vs Actual Value: 190.4\n",
      "Predicted Value: [-211.22147] vs Actual Value: -211.0\n",
      "Predicted Value: [-173.3873] vs Actual Value: -173.2\n",
      "Predicted Value: [177.93004] vs Actual Value: 177.8\n",
      "Predicted Value: [237.38374] vs Actual Value: 237.2\n",
      "Predicted Value: [35.601482] vs Actual Value: 35.6\n",
      "Predicted Value: [-315.71585] vs Actual Value: -315.4\n",
      "Predicted Value: [-4.034322] vs Actual Value: -4.0\n",
      "Predicted Value: [-67.09128] vs Actual Value: -67.0\n",
      "Predicted Value: [-274.2784] vs Actual Value: -274.0\n",
      "Predicted Value: [55.419384] vs Actual Value: 55.4\n",
      "Predicted Value: [-276.08002] vs Actual Value: -275.8\n",
      "Predicted Value: [91.45193] vs Actual Value: 91.4\n",
      "Predicted Value: [-227.43611] vs Actual Value: -227.2\n",
      "Predicted Value: [84.24542] vs Actual Value: 84.2\n",
      "Predicted Value: [-77.90105] vs Actual Value: -77.8\n",
      "Predicted Value: [62.625896] vs Actual Value: 62.6\n",
      "Predicted Value: [-43.67012] vs Actual Value: -43.6\n",
      "Predicted Value: [-241.84914] vs Actual Value: -241.6\n",
      "Predicted Value: [-162.57753] vs Actual Value: -162.4\n",
      "Predicted Value: [-294.0963] vs Actual Value: -293.8\n",
      "Predicted Value: [127.484474] vs Actual Value: 127.4\n",
      "Predicted Value: [91.45193] vs Actual Value: 91.4\n",
      "Predicted Value: [275.21793] vs Actual Value: 275.0\n",
      "Predicted Value: [129.2861] vs Actual Value: 129.2\n",
      "Predicted Value: [-101.322205] vs Actual Value: -101.2\n",
      "Predicted Value: [259.0033] vs Actual Value: 258.8\n",
      "Predicted Value: [-77.90105] vs Actual Value: -77.8\n",
      "Predicted Value: [73.43565] vs Actual Value: 73.4\n",
      "Predicted Value: [53.617756] vs Actual Value: 53.6\n",
      "Predicted Value: [181.5333] vs Actual Value: 181.4\n",
      "Predicted Value: [-81.5043] vs Actual Value: -81.4\n",
      "Predicted Value: [259.0033] vs Actual Value: 258.8\n",
      "Predicted Value: [-160.7759] vs Actual Value: -160.6\n",
      "Predicted Value: [-0.4310665] vs Actual Value: -0.4\n",
      "Predicted Value: [122.0796] vs Actual Value: 122.0\n",
      "Predicted Value: [53.617756] vs Actual Value: 53.6\n",
      "Predicted Value: [-164.37917] vs Actual Value: -164.2\n",
      "Predicted Value: [-214.82474] vs Actual Value: -214.6\n",
      "Predicted Value: [286.0277] vs Actual Value: 285.8\n",
      "Predicted Value: [68.03078] vs Actual Value: 68.0\n",
      "Predicted Value: [-20.24897] vs Actual Value: -20.2\n",
      "Predicted Value: [284.22607] vs Actual Value: 284.0\n",
      "Predicted Value: [-31.058731] vs Actual Value: -31.0\n",
      "Predicted Value: [-11.24083] vs Actual Value: -11.2\n",
      "Predicted Value: [122.0796] vs Actual Value: 122.0\n",
      "Predicted Value: [163.51703] vs Actual Value: 163.4\n",
      "Predicted Value: [-216.62636] vs Actual Value: -216.4\n",
      "Predicted Value: [-312.11258] vs Actual Value: -311.8\n",
      "Predicted Value: [-303.10446] vs Actual Value: -302.8\n",
      "Predicted Value: [235.58214] vs Actual Value: 235.4\n",
      "Predicted Value: [-9.439204] vs Actual Value: -9.4\n",
      "Predicted Value: [-65.28965] vs Actual Value: -65.2\n",
      "Predicted Value: [-137.35475] vs Actual Value: -137.2\n",
      "Predicted Value: [122.0796] vs Actual Value: 122.0\n",
      "Predicted Value: [141.89749] vs Actual Value: 141.8\n",
      "Predicted Value: [-27.455479] vs Actual Value: -27.4\n",
      "Predicted Value: [-290.49304] vs Actual Value: -290.2\n",
      "Predicted Value: [-16.645714] vs Actual Value: -16.6\n",
      "Predicted Value: [219.36748] vs Actual Value: 219.2\n",
      "Predicted Value: [-315.71585] vs Actual Value: -315.4\n",
      "Predicted Value: [-245.4524] vs Actual Value: -245.2\n",
      "Predicted Value: [-189.60193] vs Actual Value: -189.4\n",
      "Predicted Value: [138.29424] vs Actual Value: 138.2\n",
      "Predicted Value: [143.69913] vs Actual Value: 143.6\n",
      "Predicted Value: [-63.488026] vs Actual Value: -63.4\n",
      "Predicted Value: [143.69913] vs Actual Value: 143.6\n",
      "Predicted Value: [172.52516] vs Actual Value: 172.4\n",
      "Predicted Value: [266.2098] vs Actual Value: 266.0\n",
      "Predicted Value: [-92.314064] vs Actual Value: -92.2\n",
      "Predicted Value: [-151.76776] vs Actual Value: -151.6\n",
      "Predicted Value: [8.57707] vs Actual Value: 8.6\n",
      "Predicted Value: [-122.94173] vs Actual Value: -122.8\n",
      "Predicted Value: [60.82427] vs Actual Value: 60.8\n",
      "Predicted Value: [-304.90607] vs Actual Value: -304.6\n",
      "Predicted Value: [-187.80031] vs Actual Value: -187.6\n",
      "Predicted Value: [-265.2703] vs Actual Value: -265.0\n",
      "Predicted Value: [-5.835949] vs Actual Value: -5.8\n",
      "Predicted Value: [147.30238] vs Actual Value: 147.2\n",
      "Predicted Value: [-113.93359] vs Actual Value: -113.8\n",
      "Predicted Value: [-45.47175] vs Actual Value: -45.4\n",
      "Predicted Value: [120.27797] vs Actual Value: 120.2\n",
      "Predicted Value: [-218.42796] vs Actual Value: -218.2\n",
      "Predicted Value: [260.8049] vs Actual Value: 260.6\n",
      "Predicted Value: [82.443794] vs Actual Value: 82.4\n",
      "Predicted Value: [-5.835949] vs Actual Value: -5.8\n",
      "Predicted Value: [201.3512] vs Actual Value: 201.2\n",
      "Predicted Value: [167.12029] vs Actual Value: 167.0\n",
      "Predicted Value: [24.791718] vs Actual Value: 24.8\n",
      "Predicted Value: [-196.80844] vs Actual Value: -196.6\n",
      "Predicted Value: [145.50075] vs Actual Value: 145.4\n",
      "Predicted Value: [-261.66702] vs Actual Value: -261.4\n",
      "Predicted Value: [-65.28965] vs Actual Value: -65.2\n",
      "Predicted Value: [-313.9142] vs Actual Value: -313.6\n",
      "Predicted Value: [296.83746] vs Actual Value: 296.6\n",
      "Predicted Value: [-131.94986] vs Actual Value: -131.8\n",
      "Predicted Value: [77.03891] vs Actual Value: 77.0\n",
      "Predicted Value: [-175.18892] vs Actual Value: -175.0\n",
      "Predicted Value: [51.816128] vs Actual Value: 51.8\n",
      "Predicted Value: [-2.2326946] vs Actual Value: -2.2\n",
      "Predicted Value: [15.783579] vs Actual Value: 15.8\n",
      "Predicted Value: [-317.5175] vs Actual Value: -317.2\n",
      "Predicted Value: [-209.41985] vs Actual Value: -209.2\n",
      "Predicted Value: [240.987] vs Actual Value: 240.8\n",
      "Predicted Value: [-2.2326946] vs Actual Value: -2.2\n",
      "Predicted Value: [116.67471] vs Actual Value: 116.6\n",
      "Predicted Value: [-277.88168] vs Actual Value: -277.6\n",
      "Predicted Value: [-4.034322] vs Actual Value: -4.0\n",
      "Predicted Value: [206.75607] vs Actual Value: 206.6\n",
      "Predicted Value: [-113.93359] vs Actual Value: -113.8\n",
      "Predicted Value: [-142.75963] vs Actual Value: -142.6\n",
      "Predicted Value: [210.35933] vs Actual Value: 210.2\n",
      "Predicted Value: [87.84868] vs Actual Value: 87.8\n",
      "Predicted Value: [-249.05565] vs Actual Value: -248.8\n",
      "Predicted Value: [30.196598] vs Actual Value: 30.2\n",
      "Predicted Value: [86.04705] vs Actual Value: 86.0\n",
      "Predicted Value: [-286.88983] vs Actual Value: -286.6\n",
      "Predicted Value: [48.212875] vs Actual Value: 48.2\n",
      "Predicted Value: [287.82935] vs Actual Value: 287.6\n",
      "Predicted Value: [89.6503] vs Actual Value: 89.6\n",
      "Predicted Value: [78.84054] vs Actual Value: 78.8\n",
      "Predicted Value: [199.54956] vs Actual Value: 199.4\n",
      "Predicted Value: [145.50075] vs Actual Value: 145.4\n",
      "Predicted Value: [273.41632] vs Actual Value: 273.2\n",
      "Predicted Value: [-268.87354] vs Actual Value: -268.6\n",
      "Predicted Value: [-32.86036] vs Actual Value: -32.8\n",
      "Predicted Value: [248.19351] vs Actual Value: 248.0\n",
      "Predicted Value: [154.5089] vs Actual Value: 154.4\n",
      "Predicted Value: [100.46007] vs Actual Value: 100.4\n",
      "Predicted Value: [203.15282] vs Actual Value: 203.0\n",
      "Predicted Value: [-285.08817] vs Actual Value: -284.8\n",
      "Predicted Value: [149.104] vs Actual Value: 149.0\n",
      "Predicted Value: [35.601482] vs Actual Value: 35.6\n",
      "Predicted Value: [-68.89291] vs Actual Value: -68.8\n",
      "Predicted Value: [260.8049] vs Actual Value: 260.6\n",
      "Predicted Value: [37.403107] vs Actual Value: 37.4\n",
      "Predicted Value: [-288.69144] vs Actual Value: -288.4\n",
      "Predicted Value: [51.816128] vs Actual Value: 51.8\n",
      "Predicted Value: [-61.686398] vs Actual Value: -61.6\n",
      "Predicted Value: [221.16911] vs Actual Value: 221.0\n",
      "Predicted Value: [-130.14824] vs Actual Value: -130.0\n",
      "Predicted Value: [-115.73522] vs Actual Value: -115.6\n",
      "Predicted Value: [138.29424] vs Actual Value: 138.2\n",
      "Predicted Value: [71.63403] vs Actual Value: 71.6\n",
      "Predicted Value: [71.63403] vs Actual Value: 71.6\n",
      "Predicted Value: [-328.32724] vs Actual Value: -328.0\n",
      "Predicted Value: [134.691] vs Actual Value: 134.6\n",
      "Predicted Value: [-276.08002] vs Actual Value: -275.8\n",
      "Predicted Value: [131.08774] vs Actual Value: 131.0\n",
      "Predicted Value: [210.35933] vs Actual Value: 210.2\n",
      "Predicted Value: [-108.52871] vs Actual Value: -108.4\n",
      "Predicted Value: [-88.71081] vs Actual Value: -88.6\n",
      "Predicted Value: [-238.24588] vs Actual Value: -238.0\n",
      "Predicted Value: [4.973815] vs Actual Value: 5.0\n",
      "Predicted Value: [259.0033] vs Actual Value: 258.8\n",
      "Predicted Value: [-290.49304] vs Actual Value: -290.2\n",
      "Predicted Value: [-200.41171] vs Actual Value: -200.2\n",
      "Predicted Value: [262.60654] vs Actual Value: 262.4\n",
      "Predicted Value: [-191.40356] vs Actual Value: -191.2\n",
      "Predicted Value: [71.63403] vs Actual Value: 71.6\n",
      "Predicted Value: [-231.03937] vs Actual Value: -230.8\n",
      "Predicted Value: [230.17725] vs Actual Value: 230.0\n",
      "Predicted Value: [161.7154] vs Actual Value: 161.6\n",
      "Predicted Value: [296.83746] vs Actual Value: 296.6\n"
     ]
    }
   ],
   "source": [
    "for count, x in enumerate(model_output):\n",
    "    error[count] = model_output[count] - test_y[count]\n",
    "    print(f\"Predicted Value: {model_output[count]} vs Actual Value: {test_y[count]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.23448181,  0.00473404, -0.00340271,  0.20489502,  0.08447266,\n",
       "       -0.00828171,  0.03403473, -0.26702881,  0.08935547, -0.07662964,\n",
       "        0.04216766,  0.21469116, -0.00177383, -0.14336395, -0.07012177,\n",
       "        0.12190247,  0.00473404, -0.26864624,  0.21957397,  0.24072266,\n",
       "       -0.09616089, -0.12220764,  0.07959747, -0.06523895,  0.04216766,\n",
       "       -0.0375762 , -0.0147934 ,  0.06658173,  0.23422241,  0.21957397,\n",
       "       -0.17588806, -0.2442627 ,  0.14306641, -0.25239563,  0.03077698,\n",
       "        0.19839478,  0.03403473, -0.12382507, -0.12545013, -0.06361389,\n",
       "        0.15281677, -0.06198883,  0.20489502, -0.28982544, -0.00828171,\n",
       "       -0.0147934 ,  0.23422241, -0.00340271, -0.06361389, -0.30282593,\n",
       "       -0.22146606,  0.16911316,  0.11051941, -0.00177383,  0.23095703,\n",
       "        0.14956665, -0.2035675 , -0.1401062 , -0.00991058, -0.26538086,\n",
       "       -0.09127808,  0.07633972,  0.04053497, -0.04571342, -0.11894989,\n",
       "       -0.25564575, -0.15312195, -0.02293015, -0.19869995, -0.06361389,\n",
       "        0.08773804,  0.12028503,  0.07633972,  0.13330078, -0.00828171,\n",
       "        0.05355835, -0.25564575, -0.10430145, -0.07500458, -0.29144287,\n",
       "        0.13818359,  0.09262085, -0.29467773,  0.21142578,  0.14468384,\n",
       "        0.14630127,  0.20330811,  0.24234009, -0.0473423 , -0.21658325,\n",
       "        0.17073059,  0.00473404, -0.02293015,  0.03403473, -0.2507782 ,\n",
       "       -0.1466217 ,  0.03240204, -0.2182312 ,  0.18536377,  0.19351196,\n",
       "        0.04379272, -0.3190918 ,  0.11376953,  0.10075378,  0.10075378,\n",
       "        0.15933228,  0.14793396,  0.22119141, -0.22636414, -0.00665474,\n",
       "       -0.28167725, -0.09616089, -0.16452026, -0.19541931,  0.03728485,\n",
       "       -0.20030212, -0.0571022 ,  0.02589798,  0.06819916, -0.31585693,\n",
       "       -0.0375762 , -0.23448181, -0.07174683,  0.20980835,  0.05355835,\n",
       "        0.19676208,  0.21792603, -0.15800476, -0.10917664,  0.12190247,\n",
       "        0.13330078,  0.10238647,  0.16911316, -0.19541931,  0.16748047,\n",
       "        0.11213684,  0.06819916, -0.23124695,  0.06332397, -0.15962219,\n",
       "        0.22119141, -0.14498138, -0.19706726,  0.05844116,  0.00799179,\n",
       "       -0.11569214,  0.05192566,  0.15606689,  0.21957397,  0.19676208,\n",
       "        0.00473404, -0.21333313, -0.01967525, -0.23776245, -0.23776245,\n",
       "        0.02589798, -0.11243439,  0.05680847,  0.16096497, -0.00340271,\n",
       "       -0.10917664, -0.12708282,  0.21792603, -0.21984863, -0.26052856,\n",
       "       -0.1173172 ,  0.22119141, -0.10917664, -0.18240356,  0.09262085,\n",
       "       -0.08151245, -0.19055176, -0.27679443, -0.0847702 , -0.01153946,\n",
       "       -0.04571342, -0.21333313,  0.00148392,  0.07471466, -0.22473145,\n",
       "       -0.17753601, -0.05547905, -0.11569214, -0.1466217 ,  0.14956665,\n",
       "       -0.07012177, -0.22961426, -0.0375762 ,  0.22283936,  0.0242691 ,\n",
       "       -0.30282593, -0.0473423 , -0.20193481,  0.15119934,  0.24234009,\n",
       "        0.04216766,  0.05518341,  0.20330811,  0.15771484,  0.10725403,\n",
       "        0.03728485, -0.00665474,  0.21630859, -0.24588013, -0.15800476,\n",
       "       -0.15962219,  0.06169891,  0.03077698, -0.12708282, -0.16775513,\n",
       "       -0.27029419, -0.1173172 ,  0.21469116, -0.09941864, -0.1791687 ,\n",
       "       -0.20521545,  0.00148392, -0.22796631, -0.30282593, -0.15312195,\n",
       "       -0.12220764, -0.13034058, -0.1791687 ,  0.12353516, -0.17266846,\n",
       "       -0.25727844, -0.00828171, -0.00828171, -0.14336395, -0.24588013,\n",
       "        0.21957397, -0.08965302, -0.17753601,  0.23910522,  0.11865234,\n",
       "        0.13980103, -0.22796631,  0.14956665,  0.05355835, -0.12708282,\n",
       "        0.23583984,  0.06006622,  0.04542542, -0.23124695, -0.22146606,\n",
       "       -0.14336395, -0.23936462, -0.19381714,  0.11538696, -0.11243439,\n",
       "       -0.15962219, -0.26052856,  0.18699646, -0.20030212,  0.03077698,\n",
       "       -0.26538086, -0.26379395, -0.21495056, -0.1856842 , -0.14172363,\n",
       "       -0.0571022 , -0.29467773,  0.24234009,  0.23745728, -0.32723999,\n",
       "        0.14306641,  0.16584778, -0.08639908,  0.08935547, -0.20030212,\n",
       "        0.01449966, -0.27679443, -0.20030212,  0.02751923,  0.14793396,\n",
       "       -0.22146606, -0.32723999, -0.28982544, -0.01316643, -0.29794312,\n",
       "       -0.20193481,  0.14468384,  0.24234009, -0.02130222, -0.02781224,\n",
       "        0.0503006 , -0.04896927, -0.02618504, -0.11080933, -0.29632568,\n",
       "        0.02101135, -0.17753601,  0.21630859,  0.10238647, -0.19381714,\n",
       "        0.18048096, -0.06523895, -0.21333313, -0.27679443, -0.03269458,\n",
       "        0.20654297,  0.18862915, -0.16452026, -0.2507782 , -0.06686401,\n",
       "       -0.03432178,  0.17724609,  0.08935547, -0.24263   ,  0.15119934,\n",
       "        0.22772217, -0.29632568,  0.11376953,  0.17233276, -0.31259155,\n",
       "       -0.09616089,  0.09423828,  0.04053497, -0.01316643, -0.09616089,\n",
       "       -0.12382507,  0.17884827,  0.02101135, -0.0392046 , -0.08965302,\n",
       "       -0.00502968, -0.02130222, -0.32073975, -0.28167725, -0.30770874,\n",
       "        0.08285522, -0.27679443, -0.09290314,  0.08610535, -0.28982544,\n",
       "       -0.14498138,  0.14144897, -0.22146606, -0.18730164,  0.1300354 ,\n",
       "        0.18374634,  0.00148392, -0.31585693, -0.03432178, -0.09127808,\n",
       "       -0.27841187,  0.01938248, -0.2800293 ,  0.05192566, -0.2361145 ,\n",
       "        0.04542542, -0.1010437 ,  0.02589798, -0.07012177, -0.24913025,\n",
       "       -0.17753601, -0.29632568,  0.08447266,  0.05192566,  0.21792603,\n",
       "        0.08610535, -0.12220764,  0.20330811, -0.1010437 ,  0.03565216,\n",
       "        0.01775742,  0.13330078, -0.10430145,  0.20330811, -0.17588806,\n",
       "       -0.03106651,  0.07959747,  0.01775742, -0.1791687 , -0.22473145,\n",
       "        0.22772217,  0.03077698, -0.04896927,  0.22607422, -0.05873108,\n",
       "       -0.04083061,  0.07959747,  0.11703491, -0.22636414, -0.31259155,\n",
       "       -0.30447388,  0.18214417, -0.0392046 , -0.08965302, -0.15475464,\n",
       "        0.07959747,  0.0974884 , -0.05547905, -0.29302979, -0.04571342,\n",
       "        0.16748047, -0.31585693, -0.25239563, -0.20193481,  0.09423828,\n",
       "        0.09912109, -0.08802414,  0.09912109,  0.12516785,  0.20980835,\n",
       "       -0.11406708, -0.16775513, -0.02293015, -0.14172363,  0.0242691 ,\n",
       "       -0.30606079, -0.20030212, -0.27029419, -0.03594875,  0.10238647,\n",
       "       -0.1335907 , -0.07174683,  0.07797241, -0.22796631,  0.20489502,\n",
       "        0.04379272, -0.03594875,  0.15119934,  0.12028503, -0.00828171,\n",
       "       -0.20843506,  0.10075378, -0.26702881, -0.08965302, -0.31420898,\n",
       "        0.23745728, -0.14985657,  0.03890991, -0.18891907,  0.01612854,\n",
       "       -0.03269458, -0.01642132, -0.31747437, -0.21984863,  0.18699646,\n",
       "       -0.03269458,  0.07471466, -0.28167725, -0.03432178,  0.15606689,\n",
       "       -0.1335907 , -0.15962219,  0.15933228,  0.04867554, -0.25564575,\n",
       "       -0.00340271,  0.04705048, -0.28982544,  0.0128746 ,  0.2293396 ,\n",
       "        0.0503006 ,  0.04053497,  0.14956665,  0.10075378,  0.21630859,\n",
       "       -0.27352905, -0.06035995,  0.19351196,  0.10890198,  0.06006622,\n",
       "        0.15281677, -0.28817749,  0.10400391,  0.00148392, -0.09290314,\n",
       "        0.20489502,  0.00310516, -0.29144287,  0.01612854, -0.08639908,\n",
       "        0.16911316, -0.14823914, -0.13522339,  0.09423828,  0.03403473,\n",
       "        0.03403473, -0.32723999,  0.09098816, -0.2800293 ,  0.08773804,\n",
       "        0.15933228, -0.12870789, -0.11080933, -0.24588013, -0.02618504,\n",
       "        0.20330811, -0.29302979, -0.2117157 ,  0.20654297, -0.2035675 ,\n",
       "        0.03403473, -0.23936462,  0.17724609,  0.11538696,  0.23745728])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Accuracy\n",
    "#correct = 0\n",
    "\n",
    "#for count, x in enumerate(predicted_labels):\n",
    "#    if x == test_y[count]:\n",
    "#        correct +=1\n",
    "\n",
    "        \n",
    "#f\"The model accuracy is {correct/count}\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
